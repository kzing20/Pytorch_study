{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"19oiZpJyqRxOiO5cQgGX0PKeAOO7UPiWl","authorship_tag":"ABX9TyP+wq6OfdlYkXILuHJaiOiZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## 전이학습(Transfer Learning)\n","전이학습이란 기존의 잘 알려진 데이터 혹은 사전학습된 모델을 업무 효율 증대나 도메인 확장을 위해 사용하는 학습을 의미한다. 따라서 전이학습은 인공지능 분야에서 매우 중요한 연구 중 하나이며 다양한 방법론들이 존재한다. 잘 학습된 모델을 재사용하는 방법에 대해서 알아보자."],"metadata":{"id":"yMqh8lx6E7aA"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"Kbva3Ze2E28r","executionInfo":{"status":"ok","timestamp":1705159502589,"user_tz":-540,"elapsed":12114,"user":{"displayName":"김징징","userId":"01805882568357009174"}}},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import trange"]},{"cell_type":"markdown","source":["### 1.GPU 연산 확인\n"],"metadata":{"id":"Fld9zftSIYnf"}},{"cell_type":"code","source":["# GPU VS CPU\n","#현재 가능한 장치를 확인한다.\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GXZeKqiyIXV_","executionInfo":{"status":"ok","timestamp":1705159502907,"user_tz":-540,"elapsed":320,"user":{"displayName":"김징징","userId":"01805882568357009174"}},"outputId":"56e81418-8383-4097-f246-76e0dcaf4511"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"markdown","source":["### 2. CIFAR10 데이터 불러오기"],"metadata":{"id":"mjldcF1_I6Wu"}},{"cell_type":"code","source":["#CIFAR10: 클래스 10개를 가진 이미지 데이터\n","#'plane','car','bird','cat','deer','dog','frog','horse','ship','truck'\n","\n","#데이터 불러오기 및 전처리 작업\n","transform = transforms.Compose([transforms.RandomCrop(32,padding=4),\n","                                transforms.ToTensor(),\n","                                transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n","test_transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",")\n","trainset = torchvision.datasets.CIFAR10(root='./data',train=True,\n","                                        download=True,transform=transform)\n","trainloader= torch.utils.data.DataLoader(trainset,batch_size=8,shuffle=True)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data',train=False,\n","                                        download=True,transform=test_transform)\n","testloader= torch.utils.data.DataLoader(testset,batch_size=8,shuffle=True)"],"metadata":{"id":"6RUmrrIVItAK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705159510850,"user_tz":-540,"elapsed":7947,"user":{"displayName":"김징징","userId":"01805882568357009174"}},"outputId":"8313b30c-2af3-4736-8f5c-91c0f836041c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:01<00:00, 92520883.70it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}]},{"cell_type":"markdown","source":["### 3. Pretrained model 불러오기\n","파이토치에서는 다양한 사전 학습된 모델을 제공하고 있다."],"metadata":{"id":"Qof8gAnMJcQu"}},{"cell_type":"code","source":["#ResNet18 불러오기\n","#weights='DEFAULT'를 하면 ResNet18 IMAGENET1K_V1 구조와 사전 학습된 파라메타를 모두 불러온다.\n","#weights=False를 하면 ResNet18 구조만 불러온다.\n","# 모델과 텐서에 .to(device) 를 붙여야만 GPU연산이 가능\n","\n","model = torchvision.models.resnet18(weights='DEFAULT')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0CAmzTI4JbB9","executionInfo":{"status":"ok","timestamp":1705159511548,"user_tz":-540,"elapsed":700,"user":{"displayName":"김징징","userId":"01805882568357009174"}},"outputId":"ce378b2f-8ce5-4847-932c-d1c3505d6b66"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 121MB/s]\n"]}]},{"cell_type":"code","source":["print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"guKgCOFdKABb","executionInfo":{"status":"ok","timestamp":1705159511549,"user_tz":-540,"elapsed":10,"user":{"displayName":"김징징","userId":"01805882568357009174"}},"outputId":"cdb12c60-4c60-49c4-8dba-9efe9c09ace5"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["model.conv1"],"metadata":{"id":"TuKnq76UKBkp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705159511549,"user_tz":-540,"elapsed":7,"user":{"displayName":"김징징","userId":"01805882568357009174"}},"outputId":"b923d777-6397-419a-d80e-38c6eac4b1f0"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#모델의 구조를 보면 마지막 출력 노드가 1000개라는 것을 알 수 있다.\n","#이는 1000개의 클래스를 가진 ImageNet 데이터를 이용하여 사전학습된 모델이기 때문이다.\n","#따라서 우리가 사용하는 CIFAR10 데이터에 맞게 출력층의 노드를 10개로 변경해야만 한다.\n","\n","model.conv1=  nn.Conv2d(3,64,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)\n","model.fc = nn.Linear(512,10)\n","model= model.to(device)"],"metadata":{"id":"hEWWpLCRzscK","executionInfo":{"status":"ok","timestamp":1705159511831,"user_tz":-540,"elapsed":285,"user":{"displayName":"김징징","userId":"01805882568357009174"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oZeeHPME0IH6","executionInfo":{"status":"ok","timestamp":1705159511832,"user_tz":-540,"elapsed":11,"user":{"displayName":"김징징","userId":"01805882568357009174"}},"outputId":"d56badd2-4caf-43ab-ca25-b0c758671c6d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"markdown","source":["### 4. 손실함수와 최적화 방법 정의"],"metadata":{"id":"6kf1V5aOKbBQ"}},{"cell_type":"code","source":["criterion=nn.CrossEntropyLoss()\n","optimizer=optim.Adam(model.parameters(),lr=1e-4,weight_decay=1e-2)"],"metadata":{"id":"aT-F6oJXKkh4","executionInfo":{"status":"ok","timestamp":1705159511832,"user_tz":-540,"elapsed":9,"user":{"displayName":"김징징","userId":"01805882568357009174"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["### 5. 사전학습 모델을 이용한 학습"],"metadata":{"id":"LnIgRs6wKdql"}},{"cell_type":"code","source":["num_epochs = 20\n","ls = 2\n","pbar = trange(num_epochs)\n","\n","for epoch in pbar:\n","  correct = 0\n","  total = 0\n","  running_loss = 0.0\n","  for data in trainloader:\n","    inputs,labels = data[0].to(device), data[1].to(device)\n","\n","    optimizer.zero_grad()\n","    outputs= model(inputs)\n","    loss = criterion(outputs,labels)\n","    loss.backward()\n","    optimizer.step()\n","\n","    running_loss +=loss.item()\n","    _,predicted = torch.max(outputs.detach(),1)\n","    total +=labels.size(0)\n","    correct += (predicted==labels).sum().item()\n","\n","  cost = running_loss/len(trainloader)\n","  acc = 100*correct/total\n","\n","  if cost<ls:\n","    ls = cost\n","    torch.save(model.state_dict(),'./cifar10_resnet18.pth')\n","  pbar.set_postfix({'loss ': cost, 'train acc ':acc})\n"],"metadata":{"id":"6FnhltzmKkzo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705161549305,"user_tz":-540,"elapsed":2037482,"user":{"displayName":"김징징","userId":"01805882568357009174"}},"outputId":"70e992bb-8cae-4c9d-cdc3-a675e6d89638"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [33:57<00:00, 101.86s/it, loss =0.55, train acc =83.1]\n"]}]},{"cell_type":"markdown","source":["### 6. 모델 평가"],"metadata":{"id":"Zh2vIlZEKhYg"}},{"cell_type":"code","source":["model = torchvision.models.resnet18(weights=None)\n","model.conv1=  nn.Conv2d(3,64,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)\n","model.fc = nn.Linear(512,10)\n","model= model.to(device)\n","model.load_state_dict(torch.load('./cifar10_resnet18.pth'))"],"metadata":{"id":"KErWv9-wKlQP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705161579036,"user_tz":-540,"elapsed":264,"user":{"displayName":"김징징","userId":"01805882568357009174"}},"outputId":"3379d264-b519-49e2-ea38-789aed7af91c"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["correct = 0\n","total = 0\n","with torch.no_grad():\n","  model.eval()\n","  for data in testloader:\n","    images,labels=data[0].to(device),data[1].to(device)\n","    outputs = model(images)\n","    _,predicted = torch.max(outputs.data,1)\n","    total+=labels.size(0)\n","    correct+=(predicted==labels).sum().item()\n","\n","print(\"Accuracy of the network on the 10000 test images: %d %%\" %(100*correct/total))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aKjehQAL4zoa","executionInfo":{"status":"ok","timestamp":1705161589427,"user_tz":-540,"elapsed":7133,"user":{"displayName":"김징징","userId":"01805882568357009174"}},"outputId":"ec4eae9e-a288-40f3-ded4-78caa02723dd"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 83 %\n"]}]},{"cell_type":"code","source":["import shutil\n","source_path = '/content/cifar10_resnet18.pth'\n","destination_path = '/content/drive/MyDrive/Pytorch/models'\n","\n","shutil.move(source_path, destination_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"H5cNf3w0jYMw","executionInfo":{"status":"ok","timestamp":1705161801461,"user_tz":-540,"elapsed":299,"user":{"displayName":"김징징","userId":"01805882568357009174"}},"outputId":"365c6a7b-6502-406a-8e79-22dbfe97c139"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Pytorch/models/cifar10_resnet18.pth'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]}]}